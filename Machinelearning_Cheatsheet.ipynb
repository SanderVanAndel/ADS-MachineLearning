{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machinelearning Cheatsheet Fontys minor applied data science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Sander van Andel<br>\n",
    "Sources: Minor presentations, Udacity machine learning course, the internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stylo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning practical examples:<br>\n",
    "- recommendation engine\n",
    "- credit card fraud detection\n",
    "- face recognition\n",
    "- skin vision app (check for cancer, etc.)\n",
    "- self driving cars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Classification</b>: identifying to which category a new observation belongs â€“ is most common form of supervised ML.<br>\n",
    "<b>Features</b> A feature is an individual measurable property or characteristic of a phenomenon being observed <br>\n",
    "Choosing informative, discriminating and independent features is a crucial step for effective algorithms in pattern recognition, classification and regression<br>\n",
    "<b>Labels</b> The output classes of the prediction are the labels<br>\n",
    "\n",
    "In machine learning the features are input data, and with these features the algorithm predicts the labels<br>\n",
    "This can be visualised in a scatterplot, which is a graph of plotted points that show the relationship between two sets of data.<br>\n",
    "\n",
    "ML creates a <b>decision surface</b> (2D: line, 3D: plane, n-D: <b>hyperplane</b>)<br>\n",
    "Decision surface separates one category from another so that we can easily generalize (= predict) for new datapoints<br><br>\n",
    "\n",
    "Data is usually split in a <b>train</b> and <b>test</b> set. The model is trained with the train data, and testedd by making predictions on the test set.<br>\n",
    "The 'predictive power' can be measured with accuracy.<br><br>\n",
    "\n",
    "<b>Size of train set</b><br>\n",
    "The accuracy on the train set (the data the model is trained on) increases gradually to limit when the train set size increases<br>\n",
    "The accuracy on the test set (uknown data) has an optimum. <br>\n",
    "\n",
    "<b>Underfitting</b>: When the size of the train set is <b>below</b> the optimum<br>\n",
    "- Model is too simplistic -> systematic error.\n",
    "- (Model hasn't seen enough data)\n",
    "\n",
    "<br>\n",
    "<b>Overfitting</b>: When the size of the train set is <b>greater</b> than the optimum.<br>\n",
    "- Boundary surface to specific\n",
    "- Accuracy increases on specific train set\n",
    "- Model performs worse on other sets (model is too specific for training set)\n",
    "<br>\n",
    "![title](img/train_test_size.PNG)\n",
    "![title](img/overfitting.PNG)\n",
    "![title](img/underfitting.PNG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of Algo's: <br>\n",
    "- KNN (common sense)\n",
    "- Naive Bayes (statics)\n",
    "- Decision trees\n",
    "- Random forest (Majority vote of multiple DT's)\n",
    "- SVM (linear algebra)\n",
    "- Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well is my model doing?<br>\n",
    "Can we make the quality of our model/classification measurable?<br>\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|               | Diagnosed sick | Diagnosed Healthy|\n",
    "| ------------- |:-------------: |                  |\n",
    "| Sick          |              (TP)  |               (FN)   |\n",
    "| Healthy       |                (FP)|                  (TN)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|               | Predicted: NO  | Predicted: YES|\n",
    "| ------------- |:-------------: |                  |\n",
    "| Actual: NO          |              (TN)  |               (FP)   |\n",
    "| Actual: YES       |                (FN)|                  (TP)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ratio (or %) did we classify correctly? || Most common metric<br>\n",
    "\n",
    "|               | Diagnosed sick | Diagnosed Healthy|\n",
    "| ------------- |:-------------: |                  |\n",
    "| Sick          |      1000(TP)  |       200(FN)    |\n",
    "| Healthy       |         800(FP)|          8000(TN)|\n",
    "<br><br><br><br><br>\n",
    "Accuracy = (Correct classification situations / total situations)<br>\n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)<br>\n",
    "Accuracy = (1000 + 8000) / 10.000 = 0.9 90%<br>\n",
    "<br>\n",
    "Accuracy may not be enough if the data is skewed, for example 99 records of one class, and only one of another class.<br>\n",
    "The accuracy score will be 99%, altough the model won't be able to predict any of the class with only one record<br><br>\n",
    "\n",
    "Other accuracy shortcomings:<br>\n",
    "may want to err on side of guessing innocent<br>\n",
    "may want to err on the side of guessing guilty<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avoiding False Negatives<br>\n",
    "True Positive / (True Positive + False Negative). Out of all the items that are truly positive, how many were correctly classified as positive. <br>\n",
    "Or simply, how many positive items were 'recalled' from the dataset.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avoiding False Positives\n",
    "True Positive / (True Positive + False Positive). Out of all the items labeled as positive, how many truly belong to the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
